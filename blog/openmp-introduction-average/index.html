<!DOCTYPE HTML>
<html lang="en">

  <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  <head>
    <meta charset="utf-8">
    <title>dgalizzi's ~/ OpenMP Introduction - The average example</title>
    <!-- <link href='http://fonts.googleapis.com/css?family=Comfortaa' rel='stylesheet' type='text/css'> -->
    <script type="text/javascript" src="/prettify.js"></script>
    <link rel="stylesheet" type="text/css" href="/style.css" media="screen">
    <meta name="generator" content="nanoc 3.3.6">
  </head>
  <body onload="prettyPrint()">
    <div id="main">
      dgalizzi's ~/
      <div id="top-nav">
        <nav>
        <ul>
          <li><a href="/blog/">Blog</a></li>
          <li><a href="/selections/">Selections</a></li>
          <li><a href="/spanish/">Spanish</a></li>
          <li><a href="/about/">About</a></li>
        </ul>
        </nav>
      </div>
      <div id="yield">
        <h1>OpenMP introduction - The average example</h1>

<p><strong>How to calculate the average of a vector in parallel using OpenMP?</strong> Here I&#39;ll cover two ways of doing this, the first one is the long way, intended only to show some functionality of OpenMP. Then I&#39;ll show how to do it automatically with the reduction clause.</p>

<h2>What do we need?</h2>

<ul>
<li><strong>omp_get_num_threads()</strong>: Returns the number of threads in the current parallel region.</li>
<li><strong>omp_get_thread_num()</strong>: Returns the number of the current thread, the first being zero.</li>
<li><strong>critical</strong>: Identifies a region that must be executed by a single thread at a time.</li>
</ul>

<p>Let&#39;s start with the following code:</p>

<pre><code class="prettyprint linenums">#include &lt;omp.h&gt;
#include &lt;iostream&gt;
#include &lt;vector&gt;
#include &lt;numeric&gt;
using namespace std;

// Non-parallel average function
double avg(const vector&lt;double&gt; &amp;v)
{
    double sum = accumulate(v.begin(), v.end(), 0.0);
    return sum/v.size();
}

// Parallel average function
double pavg(const vector&lt;double&gt; &amp;v)
{
    // to do
}

int main()
{
    vector&lt;double&gt; v(1000000);
    for (int i = 0 ; i &lt; v.size() ; i ++)
        v[i] = 2*i;

    cout &lt;&lt; &quot;Average: &quot; &lt;&lt; avg(v) &lt;&lt; endl;
    cout &lt;&lt; &quot;Parallel average: &quot; &lt;&lt; pavg(v) &lt;&lt; endl;

    return 0;
}
</code></pre>

<p>Here we have two versions of the average function, we will focus on the parallel version. To do this, we will need to follow the next steps:</p>

<ol>
<li>Get the number of running threads.</li>
<li>Calculate, for each thread, the starting and ending indexes of the iteration.</li>
<li>Locally calculate the sum in the previously calculated interval.</li>
<li>Accumulate all the locally sums into a global result.</li>
</ol>

<p>For example, assume we have a vector with 100 elements, and four threads. The first thread will calculate the sum of the interval [0, 25), the second of the interval [25, 50), the third [50, 75) and the fourth [75, 100). To do this, we divide the size of the vector by the number of threads, and obtain the size of each interval. This could be done like this:</p>

<pre><code class="prettyprint">#pragma omp parallel
{
    int t = omp_get_thread_num();
    int n = omp_get_num_threads();

    int size = v.size()/n; // v is the vector
    int start = t*size;
    int end = (t+1)*size;
}
</code></pre>

<p>Let&#39;s review this code with the previous example, 100 elements and four threads.</p>

<ul>
<li>First thread:

<ul>
<li>t     = 0</li>
<li>n     = 4</li>
<li>size  = 25 (100/4)</li>
<li>start = 0</li>
<li>end   = 25</li>
</ul></li>
<li>Second thread:

<ul>
<li>t     = 1</li>
<li>n     = 4</li>
<li>size  = 25</li>
<li>start = 25</li>
<li>end   = 50</li>
</ul></li>
<li>Third thread:

<ul>
<li>t     = 2</li>
<li>n     = 4</li>
<li>size  = 25</li>
<li>start = 50</li>
<li>end   = 75</li>
</ul></li>
<li>Fourth thread:

<ul>
<li>t     = 3</li>
<li>n     = 4</li>
<li>size  = 25</li>
<li>start = 75</li>
<li>end   = 100</li>
</ul></li>
</ul>

<p>This looks fine, each for loop will sum the interval [start, end) and we&#39;re done. There is one problem though, what if the size of the vector is not divisible by the number of threads?. Think of 100 elements with three threads instead. Dividing (integer division) 100 by 3, gives 33. In that case the last thread will sum the interval [66, 99). To avoid this all we have to do is assign the end of the last thread to the size of the vector (this could be done better). Then, the code, including the for loop to calculate the local sum, is:</p>

<pre><code class="prettyprint">#pragma omp parallel
{
    int t = omp_get_thread_num();
    int n = omp_get_num_threads();

    int size = v.size()/n; // v is the vector
    int start = t*size;
    int end = (t == (n-1) ? v.size() : (t+1)*l)

    double sum = 0;
    for (int i = start ; i &lt; end ; i ++)
        sum += v[i];
}
</code></pre>

<p>All we need to do now is accumulate the sum of all threads into a global variable to obtain the total sum. Special care has to be taken here, the total sum is shared among all threads, one thread might read an old value, and then write a wrong value. To make sure the variable is accessed only by one thread at a time, we use the <strong>critical</strong> directive. The pavg function is:</p>

<pre><code class="prettyprint">// Parallel average function
double pavg(const vector&lt;double&gt; &amp;v)
{
    double total_sum = 0;
    #pragma omp parallel
    {
        int t = omp_get_thread_num();
        int n = omp_get_num_threads();

        int size = v.size()/n; // v is the vector
        int start = t*size;
        int end = (t == (n-1) ? v.size() : (t+1)*l)

        double sum = 0;
        for (int i = start ; i &lt; end ; i ++)
            sum += v[i];

        #pragma omp critical
        total_sum += sum;
    }

    return total_sum/v.size();
}
</code></pre>

<p>As this is a very common operation, OpenMP provides with the reduction clause that does all this for us. The reduction clause it&#39;s used in a parallel loop, with the syntax:</p>

<pre><code>#pragma parallel for reduction(operator:total_accumulator)
</code></pre>

<p>This way OpenMP will take care of calculating a local sum for each thread and accumulating it in total_accumulator. Using the reduction clause, the final code is:</p>

<pre><code class="prettyprint linenums">#include &lt;omp.h&gt;
#include &lt;iostream&gt;
#include &lt;vector&gt;
#include &lt;numeric&gt;
using namespace std;

// Non-parallel average function
double avg(const vector&lt;double&gt; &amp;v)
{
    double sum = accumulate(v.begin(), v.end(), 0.0);
    return sum/v.size();
}

// Parallel average function
double pavg(const vector&lt;double&gt; &amp;v)
{
    double total_sum = 0;
    #pragma omp parallel for reduction(+:total_sum)
    for (int i = 0 ; i &lt; v.size() ; i ++)
        total_sum += v[i];

    return total_sum/v.size();
}

int main()
{
    vector&lt;double&gt; v(1000000);
    for (int i = 0 ; i &lt; v.size() ; i ++)
        v[i] = 2*i;

    cout &lt;&lt; &quot;Average: &quot; &lt;&lt; avg(v) &lt;&lt; endl;
    cout &lt;&lt; &quot;Parallel average: &quot; &lt;&lt; pavg(v) &lt;&lt; endl;

    return 0;
}
</code></pre>

      </div>
    </div>
  </body>
</html>
